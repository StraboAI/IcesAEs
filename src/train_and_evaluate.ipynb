{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "from time import time\n",
    "\n",
    "import numpy as np\n",
    "import optuna\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "from sklearn.metrics import balanced_accuracy_score as bas\n",
    "\n",
    "from objectives import RFobjective, RandomForestClassifier\n",
    "from utils import Dataset\n",
    "\n",
    "os.environ[\"KMP_WARNINGS\"] = \"FALSE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset(\"../data/final_filtered_catalog_for_model_training_and_eval.pkl\")\n",
    "\n",
    "# window around the trigger for training models\n",
    "w_min = 350\n",
    "w_max = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_trials = 25\n",
    "results =[]\n",
    "i=1\n",
    "wavetype = \"alignedwaves\"\n",
    "\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "for till_test_exp in dataset.till_exp_nums:\n",
    "    for rock_test_exp in dataset.rock_exp_nums:\n",
    "\n",
    "        train = dataset.catalog[~dataset.catalog.expname.isin([till_test_exp, rock_test_exp])]\n",
    "        test = dataset.catalog[dataset.catalog.expname.isin([till_test_exp, rock_test_exp])]\n",
    "\n",
    "        x_train = np.stack(train[wavetype].values)\n",
    "        x_test = np.stack(test[wavetype].values)\n",
    "        y_train = train.labels.values\n",
    "        y_test = test.labels.values\n",
    "\n",
    "        testexps = (till_test_exp, rock_test_exp)\n",
    "        rockevs = y_test.sum()\n",
    "        tillevs = len(y_test) - y_test.sum()\n",
    "\n",
    "        # limit x to first arrivals\n",
    "        x_train = np.stack(x_train)[:,350:500]\n",
    "        x_test = np.stack(x_test)[:,350:500]\n",
    "\n",
    "        # Training and eval\n",
    "        rfObjective = RFobjective(x_train, x_test, y_train, y_test)\n",
    "        for objective, model in [\n",
    "            (rfObjective, RandomForestClassifier),\n",
    "        ]:\n",
    "            t0 = time()\n",
    "            print(i, model.__name__)\n",
    "            study = optuna.create_study(direction=\"maximize\", pruner=optuna.pruners.HyperbandPruner())\n",
    "            study.optimize(objective, n_trials=n_trials)\n",
    "            study.best_params\n",
    "            clf = model(**study.best_params, n_jobs=-1)\n",
    "            clf.fit(x_train, y_train)\n",
    "            y_pred = clf.predict(x_test)\n",
    "\n",
    "            # overall accuracy\n",
    "            full_acc = accuracy_score(y_test, y_pred)\n",
    "            f1 = f1_score(y_test, y_pred)\n",
    "            f1_macro = f1_score(y_test, y_pred, average=\"macro\")\n",
    "            f1_micro = f1_score(y_test, y_pred, average=\"micro\")\n",
    "            f1_weighted = f1_score(y_test, y_pred, average=\"weighted\")\n",
    "            bal_acc = bas(y_test, y_pred)\n",
    "            roc_weighted = roc_auc_score(y_test, y_pred, average=\"weighted\")\n",
    "            roc_macro = roc_auc_score(y_test, y_pred, average=\"macro\")\n",
    "            roc_micro = roc_auc_score(y_test, y_pred, average=\"micro\")\n",
    "\n",
    "            # accuracy within each test experiment\n",
    "            till_acc = accuracy_score(y_test[y_test==0], y_pred[y_test==0])\n",
    "            rock_acc = accuracy_score(y_test[y_test==1], y_pred[y_test==1])\n",
    "\n",
    "            results.append(\n",
    "                {\n",
    "                    \"run_number\": i,\n",
    "                    \"model\": model.__name__,\n",
    "                    \"accuracy\": full_acc,\n",
    "                    \"f1\": f1,\n",
    "                    \"f1_macro\": f1_macro,\n",
    "                    \"f1_weighted\": f1_weighted,\n",
    "                    \"f1_micro\": f1_micro,\n",
    "                    \"roc_macro\": roc_macro,\n",
    "                    \"roc_weighted\": roc_weighted,\n",
    "                    \"roc_micro\": roc_micro,\n",
    "                    \"balanced_accuracy\": bal_acc,\n",
    "                    \"till_accuracy\": till_acc,\n",
    "                    \"rock_accuracy\": rock_acc,\n",
    "                    \"test_exps\": testexps,\n",
    "                    \"n_rock_evs\": rockevs,\n",
    "                    \"n_till_evs\": tillevs,\n",
    "                    \"classifier\": clf,\n",
    "                    \"clf_params\": study.best_params\n",
    "                }\n",
    "            )\n",
    "            print(f\"time: {(time()-t0):.2f}, till acc: {till_acc:.2f}, rock acc: {rock_acc:.2f}, ntill: {tillevs}, nrock: {rockevs}\" )\n",
    "        i += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.till_accuracy.mean(), res.rock_accuracy.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.groupby(\"model\")[\"accuracy\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res[\"till_test_exp\"] = res.test_exps.apply(lambda x: x[0])\n",
    "res[\"rock_test_exp\"] = res.test_exps.apply(lambda x: x[1])\n",
    "res.to_pickle(\"../data/train_test_results.pkl\")\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(res[\"n_till_evs\"], res[\"till_accuracy\"])\n",
    "plt.scatter(res[\"n_rock_evs\"], res[\"rock_accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.groupby([\"till_test_exp\",\"model\"])[\"till_accuracy\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.groupby([\"rock_test_exp\",\"model\"])[\"rock_accuracy\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30,5))\n",
    "sns.boxplot(data=res, x=\"run_number\", y=\"balanced_accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_by_testexps = pd.DataFrame(res.groupby(\"test_exps\")[\"balanced_accuracy\"].mean()).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_by_test_exp = res.groupby(\"run_number\").aggregate(\n",
    "    {\n",
    "        \"balanced_accuracy\": np.mean,\n",
    "        \"till_test_exp\": lambda x: list(x)[0],\n",
    "        \"rock_test_exp\": lambda x: list(x)[0]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_by_test_exp = acc_by_test_exp.pivot(index=\"till_test_exp\", columns=\"rock_test_exp\", values=\"balanced_accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,7))\n",
    "sns.heatmap(\n",
    "    acc_by_test_exp,\n",
    "    cmap=\"seismic\",\n",
    "    vmin=0, vmax=1,\n",
    "    annot=True, fmt=\".2f\"\n",
    ")\n",
    "plt.title(\"Mean accuracy by test set experiment pair (till, rock)\")\n",
    "plt.ylabel(\"Till experiment #\")\n",
    "plt.xlabel(\"Rock experiment #\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.groupby(\"rock_test_exp\")[\"rock_accuracy\"].mean().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.groupby(\"rock_test_exp\")[\"f1\"].mean().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.groupby(\"till_test_exp\")[\"till_accuracy\"].mean().plot.bar()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "54a015295a2a7ccdef8df99cf8d30eefc902137aba3756620e70516a1c475ac3"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 ('AE_pipeline')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
